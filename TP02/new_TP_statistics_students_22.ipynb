{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vHxS3VcZ86wa"
      },
      "source": [
        "# IMA207 - Practical work on SAR statistics\n",
        "\n",
        "### Emanuele DALSASSO, Florence TUPIN\n",
        "\n",
        "### Statistics and despeckling\n",
        "\n",
        "The practical work is divided in 3 parts \n",
        "\n",
        "- A. empirical checking of the distributions seen in course for single look complex images \n",
        "- B.  computation of equivalent number of looks using images of physically homogeneous areas\n",
        "- C. spatial multi-looking and implementation of the Lee filter\n",
        "\n",
        "You have at your disposal a set of images coming from different sensors and with different characteristics on the same area of Flevoland in Netherlands (for each sensor and acquisition mode, an homogeneous area of sea has been selected with *mer* extension, and an area of farmland with  *centre* extension):\n",
        "- Sentinel-1 sensor (ESA), SLC (Single look Complex) data and GRD (Ground Range Detected) data ;\n",
        "- ERS sensor (ESA), PRI product (ground range data);\n",
        "- Alos sensor (JAXA), SLC (Single look Complex) data.\n",
        "\n",
        "Some useful functions are available in the file *mvalab.py*.\n",
        "\n",
        "### Name: MALECOT Jeanne\n",
        "\n",
        "#### Instructions\n",
        "\n",
        "To solve this practical session, answer the questions below. Then export the notebook with the answers using the menu option **File -> Download as -> Notebook (.ipynb)**. Then [submit the resulting file on e-campus by next week. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4NgoZfsEcW6"
      },
      "source": [
        "### Import the libraries and packages we are going to use\n",
        "The following cell imports all that is going to be necessary for the practical work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O3Lp7xfMElLD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' n'est pas reconnu en tant que commande interne\n",
            "ou externe, un programme exï¿½cutable ou un fichier de commandes.\n"
          ]
        }
      ],
      "source": [
        "!wget https://perso.telecom-paristech.fr/tupin/TPSAR/mvalab.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU9jOLPZAlZ7"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "from scipy import signal\n",
        "import scipy.signal\n",
        "import scipy as spy\n",
        "import scipy.fftpack\n",
        "from scipy import ndimage\n",
        "from scipy import special\n",
        "from scipy import ndimage\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import mvalab as mvalab\n",
        "from urllib.request import urlopen\n",
        "import cmath\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [15, 15]\n",
        "plt.rcParams['figure.max_open_warning'] = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE0-4mm-JSH7"
      },
      "source": [
        "## A. Single look data distributions \n",
        "In this part, we will use an SLC (Single Look Complex) image and analyze its pdf. \n",
        "The image has been acquired by the Sentinel-1 sensor over the Lelystad zone (very flat area with fields crops). \n",
        "Vizualize the amplitude image and interpret it. You may want to have a look to an [optical image](https://goo.gl/maps/JJcYcRjMKj1p6uqW8) of the area\n",
        "\n",
        "N.B.: An amplitude image is given by the modulus of the electro-magnetic field and intensity is the square of the amplitude (proportional to the signal power). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLSWCECQJjzm"
      },
      "outputs": [],
      "source": [
        "pageweb=\"https://perso.telecom-paristech.fr/tupin/TPSAR/pilelely/\"\n",
        "image='Lely.CXF'\n",
        "im_slc_senti_lely_liste=mvalab.imz2mat(pageweb+image);\n",
        "im_slc_senti_lely = im_slc_senti_lely_liste[0]\n",
        "ncol=im_slc_senti_lely_liste[1]\n",
        "nlig=im_slc_senti_lely_liste[2]\n",
        "\n",
        "mvalab.visusar(im_slc_senti_lely[0:1000,0:2000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpstbS21KD7v"
      },
      "source": [
        "\n",
        "#### Data distributions for an homogeneous area\n",
        "Select a physically homogeneous area (you can zoom and see coordinates as you move the arrow on the image) and compute the distribution of the real part, imaginary part, phase, intensity and amplitude. Some useful functions are:\n",
        "- `np.angle`\n",
        "- `np.real`\n",
        "- `np.imag` \n",
        "\n",
        "Then, estimate the coefficient of variation:  \n",
        "$\\gamma=\\frac{\\sigma}{\\mu}$ using intensity data (square of the modulus of the complex field)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peirRe7yAlZ_"
      },
      "outputs": [],
      "source": [
        "# Select a crop of the image (around 150 by 150 pixels)\n",
        "# which is physically homogeneous \n",
        "crop_slc = im_slc_senti_lely[...] #complete\n",
        "mvalab.visusar(crop_slc)\n",
        "\n",
        "# Compute amplitude, intensity, phase, real and imaginary part\n",
        "amp_senti_lely = ... #complete\n",
        "int_senti_lely = ... #complete\n",
        "ph_senti_lely = ... #complete\n",
        "real_senti_lely = ... #complete\n",
        "imag_senti_lely = ... #complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rltrId_r86w9"
      },
      "outputs": [],
      "source": [
        "# Plot the histograms and verify they match the theoretical distribution\n",
        "# Use the right range of values to plot the histogram \n",
        "# Choose the right distribution to do the fitting\n",
        "\n",
        "# fitting of the distributions \n",
        "# use the following ones :\n",
        "# Gaussian pdf : scipy.stats.norm\n",
        "# Rayleigh pdf : scipy.stats.rayleigh\n",
        "# Exponential pdf : scipy.stats.expon\n",
        "\n",
        "#example for real part of the data \n",
        "plt.figure()\n",
        "_, bins, _ = plt.hist(real_senti_lely.ravel(),bins='auto',density=True,range=[-100,100])  # Gaussian distribution\n",
        "mu, sigma = scipy.stats.norm.fit(real_senti_lely)\n",
        "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma) \n",
        "plt.plot(bins, best_fit_line)\n",
        "plt.title('histogram of real part')\n",
        "plt.show()\n",
        "\n",
        "#complete for imaginary part: Gaussian distribution\n",
        "plt.figure()\n",
        "... #complete\n",
        "plt.plot(bins, best_fit_line)\n",
        "plt.title('histogram of imaginary part')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#complete for phase data: Uniform distribution\n",
        "plt.figure()\n",
        "plt.hist(ph_senti_lely.ravel(),bins='auto',density=True,range=[...]) #complete\n",
        "plt.title('histogram of phase')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#complete for intensity data: Exponential (Gamma) distribution\n",
        "plt.figure()\n",
        "... #complete\n",
        "plt.plot(bins, best_fit_line)\n",
        "plt.title('histogram of intensity')\n",
        "plt.show()\n",
        "\n",
        "#complete for amplitude data: Rayleigh distribution\n",
        "plt.figure()\n",
        "... #complete\n",
        "plt.plot(bins, best_fit_line)\n",
        "plt.title('histogram of amplitude')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtP2QzocAlaC"
      },
      "outputs": [],
      "source": [
        "# Compute the coefficient of variation on the homogeneous crop in intensity\n",
        "\n",
        "m_I = ... #complete\n",
        "sigma_I = ... #complete\n",
        "coeff_var_I = sigma_I/m_I\n",
        "print(coeff_var_I)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0Ztx-jfvWnI"
      },
      "source": [
        "### Question A.1. \n",
        "Did you find the distributions seen in the course ? (recapitulate them).\n",
        "Did you find the correct value for the coefficient of variation ? How would this coefficient be modified if the selected area is physically heterogeneous ? Could this coefficient be less than the theoretical value ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF5d7t_owDwb"
      },
      "source": [
        "### Answer A.1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGCkTGVb86xI"
      },
      "source": [
        "## B. Computation of the Equivalent Number of looks on homogeneous areas\n",
        "In this part you have at your disposal 2 images of a part of the sea. One is a Sentinel-1 GRD image and the other one is an ERS image. The multi-looking has been done by the data provider (ESA, European Space Agency).\n",
        "Use the value of the coefficient of variation to find the Equivalent Number of Looks (ENL) of the Sentinel-1 GRD and ERS data. \n",
        "The formula is :\n",
        "- $\\gamma_I=\\frac{1}{\\sqrt{L}}$ for intensity data \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slTRUt8k86xJ"
      },
      "outputs": [],
      "source": [
        "pageweb='https://perso.telecom-paristech.fr/tupin/TPSAR/DATA/images/'\n",
        "image = 'SentinelGRD_flevoland_mer.imw'\n",
        "im_sentigrd_mer = mvalab.imz2mat(pageweb+image)\n",
        "mvalab.visusar(np.abs(im_sentigrd_mer[0]))\n",
        "\n",
        "# compute coefficient of variation and number of looks\n",
        "coeff_var_grd = ... \n",
        "L_grd = ... #complete\n",
        "print('--- coeff var and L ---')\n",
        "print(coeff_var_grd)\n",
        "print(L_grd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62J-qeIkAlaE"
      },
      "outputs": [],
      "source": [
        "image = 'ERS_flevoland_mer.imw'\n",
        "im_ers_mer = mvalab.imz2mat(pageweb+image)\n",
        "mvalab.visusar(np.abs(im_ers_mer[0]))\n",
        "\n",
        "# compute coefficient of variation and number of looks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aodIxWowMKQ"
      },
      "source": [
        "### Question B.1\n",
        "Comment the number of looks you have found for GRD and ERS data (is it an integer value ? why not ? what does it mean ?).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV9Nof6PzDRp"
      },
      "source": [
        "### Answer B.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BApTwOUK86xL"
      },
      "source": [
        "## C. Spatial multi-looking and implementation of the Lee filter\n",
        "\n",
        "In this part we will try simple speckle reduction method using the following step :\n",
        "- first we will compute a mean filter \n",
        "- then we will compute the local coefficient of variation (using the same size for the moving window)\n",
        "- finally we will combine these two results to obtain the Lee filter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNVrwaP9zLNg"
      },
      "source": [
        "## C.1 Computation of the mean filter\n",
        "Compute the mean filter using a 2D convolution. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjy--FzTzXY8"
      },
      "outputs": [],
      "source": [
        "webpage='https://perso.telecom-paristech.fr/tupin/TPSAR/pilelely/multitemp/'\n",
        "image='lely_tuple_multitemp.IMA'\n",
        "im_lely_multitemp = mvalab.imz2mat(webpage+image)\n",
        "lely_crop_slc = im_lely_multitemp[0][:,:,0]\n",
        "\n",
        "# take the intensity \n",
        "ima_int = ... #complete\n",
        "mvalab.visusar(np.sqrt(ima_int));\n",
        "\n",
        "# create the average window\n",
        "size_window = ...\n",
        "masque_loc = ... #complete\n",
        "\n",
        "# compute the mean image (intensity data)\n",
        "ima_int_mean = ...\n",
        "\n",
        "# diplay the result\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY2pSSHNzkAb"
      },
      "source": [
        "### Question C.1\n",
        "What is the effect of the mean filter ? (advantages and drawbacks). What is the influence of the window size ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-FhIXHAztpP"
      },
      "source": [
        "### Answer C.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL-oUw1lzyFs"
      },
      "source": [
        "### C. 2 Computation of the local standard deviation and the local coefficient of variation \n",
        "\n",
        "Using convolution operations as indicated in the following code compute the local standard deviation (and visualize it) and do the same for the local coefficient of variation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzLnrpyU86xM"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# compute the variance image (var{I} = E{I^2} - E{I}^2)\n",
        "ima_int_square = ... # I^2 \n",
        "ima_int_mean_square = ... #complete E{I^2}\n",
        "ima_variance = ... # complete to compute the variance  \n",
        "\n",
        "# compute coefficient of variation\n",
        "ima_coeff_var = ...\n",
        "\n",
        "# visualize these two images to compare them "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfCoWR7L3awU"
      },
      "source": [
        "### Question C.2\n",
        "Which information is enhanced in the image of the local standard deviation ? In the image of the local coefficient of variation ? Which one is the more useful ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTnMQslc3sNR"
      },
      "source": [
        "### Answer C.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRmWP7uF86xP"
      },
      "source": [
        "### C.3 Image despeckling with Lee filter\n",
        "\n",
        "The local coefficient of variation is also used in a very famous filter for SAR images: the Lee filter. \n",
        "The principle of the filter is to combine the pixel value $I_s$ (intensity value of pixel $s$) and the local mean $\\hat{\\mu}_{s}$ depending on the local coefficient of variation $\\hat{\\gamma}_s$ with the following formula :\n",
        "$$\n",
        "  \\hat{I}_s= \\hat{\\mu}_{s}+k_s (I_s-\\hat{\\mu}_{s})\n",
        "$$\n",
        "\n",
        "and\n",
        "$$\n",
        "  k_s=1- \\frac{\\gamma_{Sp}^2}{\\hat{\\gamma}_s^2}\n",
        "$$\n",
        "\n",
        "$\\gamma_{Sp}$ is the theoretical value of the coefficient of variation for a pure speckle ($\\gamma_{Sp}=\\frac{1}{\\sqrt{L}}$ for a L-look intensity image). For an SLC image, $L=1$.\n",
        "\n",
        "Using the previous results, compute the image filtered by the Lee filter. \n",
        "Warning $k$ should be between O and 1. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ5VSHhL86xQ"
      },
      "outputs": [],
      "source": [
        "# compute ks, by taking ima_coeff_var previously computed\n",
        "ks = ... #complete\n",
        "\n",
        "# force k to have values comprised in the range [0,1]\n",
        "ks= np.clip(ks,0,1)\n",
        "mvalab.visusar(ks,0)\n",
        "\n",
        "# filter the image\n",
        "image_lee_filtered = ... #complete\n",
        "mvalab.visusar(np.sqrt(image_lee_filtered))\n",
        "plt.suptitle(u'Image denoised using Lee filter')\n",
        "mvalab.visusar(np.sqrt(ima_int))\n",
        "plt.suptitle(u'Original image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcH_SF9l3-Zu"
      },
      "source": [
        "### Question C.3\n",
        "\n",
        "Compare the results of the mean filter and the Lee filter. Study the influence of the size of the window of the filters. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASojcxlCAlaG"
      },
      "source": [
        "## Filtering of image \"Lely\" and comparison with a deep learning algorithm\n",
        "In this part, we will repeat the process done above to denoise a crop of image \"Lely\" using the Lee filter. Then, we will compare it with the result of a deep learning algorithm called SAR2SAR (https://arxiv.org/abs/2006.15037)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWs2xzZr86xW"
      },
      "source": [
        "### C.4 Denoised image: SAR2SAR\n",
        "The Lee filter presents some limits. More recent approaches to suppress noise rely on sofisticated algorithms. You can plot the image of Lely denoised using a deep learning algorthm called SAR2SAR and compare visually the result with the image filtered using the Lee filter.\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqadgR6Y5qPG"
      },
      "outputs": [],
      "source": [
        "# apply the Lee filter on the following image :\n",
        "!wget https://perso.telecom-paristech.fr/tupin/TPSAR/pilelely/multitemp/lely_tuple_multitemp.IMA\n",
        "!wget https://perso.telecom-paristech.fr/tupin/TPSAR/pilelely/multitemp/lely_tuple_multitemp.dim\n",
        "part_lely_slc = mvalab.imz2mat('lely_tuple_multitemp.IMA')\n",
        "part_lely_int = np.square(np.abs(part_lely_slc[0][:,:,0]))\n",
        "mvalab.visusar(np.sqrt(part_lely_int))\n",
        "\n",
        "# using your previous code, filter the image part_lely_int with the Lee filter \n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuJQoXLy8LrT"
      },
      "outputs": [],
      "source": [
        "# this image has already been processed by a CNN based filter\n",
        "!wget https://perso.telecom-paristech.fr/tupin/TPSAR/pilelely/denoised_SAR2SAR/lely_tuple_multitemp_SAR2SAR.IMA\n",
        "!wget https://perso.telecom-paristech.fr/tupin/TPSAR/pilelely/denoised_SAR2SAR/lely_tuple_multitemp_SAR2SAR.dim\n",
        "im_lely_multitemp_denoised = mvalab.imz2mat('lely_tuple_multitemp_SAR2SAR.IMA')\n",
        "im1_d = np.abs(im_lely_multitemp_denoised[0][:,:,0]) #amplitude\n",
        "mvalab.visusar(im1_d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXx4mlW0cU2L"
      },
      "source": [
        "##Question C.4\n",
        "Do a comparison between the CNN filtering and the Lee filter. Comment the two results. Are homogeneous areas well restored? Do the methods preserve edges and fine structures? Are artifacts introduced?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwBGbyQScZ0A"
      },
      "source": [
        "### Answer C.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSbQ5d44AlaI"
      },
      "source": [
        "## D. Method noise\n",
        "Performances of a denoising algorithm can be visually interpreted by looking at the *residual noise* (i.e. the ratio between the noisy image and the denoised image, in intensity). For a quantitative evaluation, we can look at the noise statistics, knowing that, in intensity, statistics of speckle S are:\n",
        "- $\\mu_S=1$\n",
        "- $\\sigma^2_S = \\frac{1}{L}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz8wnUX4M0OR"
      },
      "source": [
        "### Question D\n",
        "Compute the aforementioned ratio image, mean value and variance for the image restored using the Lee filter and the result of SAR2SAR. Comment the results.\n",
        "\n",
        "What is the interest of computing the method noise ? What are your conclusions for the two previous filters ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG1yYoB2NHKd"
      },
      "source": [
        "### Answer D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET-iLQdyAlaI"
      },
      "outputs": [],
      "source": [
        "# Plot the residual noise\n",
        "res_noise_lee = ... #complete\n",
        "mvalab.visusar(res_noise_lee)\n",
        "mean_lee = np.mean(res_noise_lee)\n",
        "var_lee = np.var(res_noise_lee)\n",
        "print('LEE FILTER: mean = '+str(mean_lee)+' and var = '+str(var_lee))\n",
        "\n",
        "res_noise_deep = ... #complete\n",
        "mvalab.visusar(res_noise_deep)\n",
        "mean_deep = np.mean(res_noise_deep)\n",
        "var_deep = np.var(res_noise_deep)\n",
        "print('SAR2SAR: mean = '+str(mean_deep)+' and var = '+str(var_deep))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28ByIxaOAXMu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "new_TP_statistics_students_22.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
